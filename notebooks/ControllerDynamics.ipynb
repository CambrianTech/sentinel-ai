{
    "cells": [
      {
        "cell_type": "markdown",
        "metadata": {},
        "source": [
          "# Controller Dynamics\n",
          "\n",
          "Track how the controllerâ€™s gate logits evolve during training and how they influence attention head usage."
        ]
      },
      {
        "cell_type": "code",
        "metadata": {},
        "execution_count": null,
        "outputs": [],
        "source": [
          "!pip install transformers datasets matplotlib seaborn torch"
        ]
      },
      {
        "cell_type": "code",
        "metadata": {},
        "execution_count": null,
        "outputs": [],
        "source": [
          "import torch\n",
          "import matplotlib.pyplot as plt\n",
          "import seaborn as sns\n",
          "import numpy as np\n",
          "from models.loaders.loader import load_adaptive_model, load_baseline_model\n",
          "from transformers import AutoTokenizer\n",
          "\n",
          "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
          "model_name = 'distilgpt2'\n",
          "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
          "baseline = load_baseline_model(model_name, device)\n",
          "adaptive = load_adaptive_model(model_name, baseline, device)\n",
          "controller = adaptive.controller"
        ]
      },
      {
        "cell_type": "markdown",
        "metadata": {},
        "source": [
          "## Simulate Logit Updates (or Load from Training Logs)"
        ]
      },
      {
        "cell_type": "code",
        "metadata": {},
        "execution_count": null,
        "outputs": [],
        "source": [
          "# Simulated training step logit history (replace with real logs if available)\n",
          "logit_history = []\n",
          "for step in range(20):\n",
          "    noise = torch.randn_like(controller.gate_logits) * 0.2\n",
          "    controller.gate_logits.data += noise\n",
          "    logit_history.append(controller.gate_logits.detach().cpu().clone())\n",
          "\n",
          "# Convert to tensor: (steps, layers, heads)\n",
          "logit_tensor = torch.stack(logit_history)"
        ]
      },
      {
        "cell_type": "markdown",
        "metadata": {},
        "source": [
          "## Visualize Gate Evolution"
        ]
      },
      {
        "cell_type": "code",
        "metadata": {},
        "execution_count": null,
        "outputs": [],
        "source": [
          "def plot_gate_dynamics(logits):\n",
          "    num_layers, num_heads = logits.shape[1], logits.shape[2]\n",
          "    fig, axes = plt.subplots(num_layers, 1, figsize=(12, num_layers * 2))\n",
          "\n",
          "    if num_layers == 1:\n",
          "        axes = [axes]\n",
          "    for i in range(num_layers):\n",
          "        for h in range(num_heads):\n",
          "            axes[i].plot(torch.sigmoid(logits[:, i, h]), label=f'h{h}')\n",
          "        axes[i].set_title(f'Layer {i} Gate Dynamics')\n",
          "        axes[i].set_ylabel('Sigmoid(gate logit)')\n",
          "        axes[i].legend(loc='upper right')\n",
          "    plt.xlabel('Training Step')\n",
          "    plt.tight_layout()\n",
          "    plt.show()\n",
          "\n",
          "plot_gate_dynamics(logit_tensor)"
        ]
      }
    ],
    "metadata": {
      "kernelspec": {
        "name": "python3",
        "language": "python"
      },
      "language_info": {
        "name": "python",
        "version": "3.10"
      }
    },
    "nbformat": 4,
    "nbformat_minor": 5
  }
  