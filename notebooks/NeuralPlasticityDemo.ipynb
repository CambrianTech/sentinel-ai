{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Neural Plasticity in Transformer Models\n",
    "\n",
    "This notebook demonstrates the complete neural plasticity cycle (prune → measure → grow → learn) for transformer models. This approach enables more efficient and adaptive AI systems by removing underutilized components and strategically growing new ones where needed.\n",
    "\n",
    "## Overview of Neural Plasticity\n",
    "\n",
    "Neural plasticity in transformer models follows a four-stage cycle:\n",
    "\n",
    "1. **Prune**: Remove underutilized attention heads based on metrics like entropy or magnitude\n",
    "2. **Measure**: Evaluate model performance and identify areas for improvement\n",
    "3. **Grow**: Strategically add new attention heads where they would be most beneficial\n",
    "4. **Learn**: Fine-tune the model with differential learning rates for new heads\n",
    "\n",
    "This cycle mimics biological neural plasticity, where neural connections are constantly being pruned and regrown based on usage patterns."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup\n",
    "\n",
    "First, let's install the required dependencies and set up the environment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install dependencies\n",
    "!pip install -q transformers jax jaxlib optax flax tqdm matplotlib\n",
    "\n",
    "# Clone the repository\n",
    "!git clone https://github.com/yourusername/sentinel-ai.git\n",
    "!cd sentinel-ai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "import os\n",
    "import sys\n",
    "import json\n",
    "import time\n",
    "import pickle\n",
    "import random\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "\n",
    "import jax\n",
    "import jax.numpy as jnp\n",
    "from transformers import AutoTokenizer\n",
    "\n",
    "# Add parent directory to path for imports\n",
    "sys.path.append('sentinel-ai')\n",
    "\n",
    "# Import Sentinel AI modules\n",
    "from utils.pruning.pruning_module import PruningModule\n",
    "from utils.pruning.strategies import get_strategy as get_pruning_strategy\n",
    "from utils.pruning.growth import grow_attention_heads_gradually, determine_active_heads\n",
    "from utils.head_lr_manager import HeadLRManager"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Load and Analyze Initial Model\n",
    "\n",
    "We'll start by loading a pre-trained transformer model and analyzing its structure."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set random seed for reproducibility\n",
    "SEED = 42\n",
    "random.seed(SEED)\n",
    "np.random.seed(SEED)\n",
    "\n",
    "# Model selection\n",
    "MODEL_NAME = \"distilgpt2\"  # A smaller model for faster experimentation\n",
    "\n",
    "# Create pruning module\n",
    "pruning_module = PruningModule(MODEL_NAME)\n",
    "\n",
    "# Load model\n",
    "print(f\"Loading model {MODEL_NAME}...\")\n",
    "success = pruning_module.load_model()\n",
    "\n",
    "if not success:\n",
    "    raise RuntimeError(f\"Failed to load model {MODEL_NAME}\")\n",
    "\n",
    "# Get original parameters\n",
    "original_params = pruning_module.model.params\n",
    "\n",
    "# Model structure information\n",
    "print(f\"Model name: {MODEL_NAME}\")\n",
    "print(f\"Number of layers: {pruning_module.num_layers}\")\n",
    "print(f\"Heads per layer: {pruning_module.num_heads}\")\n",
    "print(f\"Total heads: {pruning_module.num_layers * pruning_module.num_heads}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analyze Head Activity in Original Model\n",
    "\n",
    "Let's check which attention heads are active in the original model and visualize their distribution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Determine active heads in original model\n",
    "original_active_heads = determine_active_heads(pruning_module, original_params)\n",
    "print(f\"Original model has {len(original_active_heads)} active heads out of {pruning_module.num_layers * pruning_module.num_heads} total\")\n",
    "\n",
    "# Function to visualize head map\n",
    "def visualize_head_map(pruning_module, active_heads, title=\"Attention Head Map\"):\n",
    "    \"\"\"Create a visual representation of active/inactive heads\"\"\"\n",
    "    num_layers = pruning_module.num_layers\n",
    "    num_heads = pruning_module.num_heads\n",
    "    \n",
    "    # Create a matrix of active heads (1=active, 0=inactive)\n",
    "    head_matrix = np.zeros((num_layers, num_heads))\n",
    "    for layer_idx, head_idx in active_heads:\n",
    "        head_matrix[layer_idx, head_idx] = 1\n",
    "    \n",
    "    # Create figure\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.imshow(head_matrix, cmap='viridis', interpolation='none')\n",
    "    plt.title(title)\n",
    "    plt.xlabel('Head Index')\n",
    "    plt.ylabel('Layer Index')\n",
    "    plt.colorbar(ticks=[0, 1], label='Active Status')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# Visualize original model's head map\n",
    "visualize_head_map(pruning_module, original_active_heads, \"Original Model Head Map\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluate Original Model Performance\n",
    "\n",
    "Let's establish a baseline by evaluating the original model's performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluation samples\n",
    "eval_samples = [\n",
    "    \"The neural network model processes data through multiple layers of computation.\",\n",
    "    \"Artificial intelligence systems can learn from experience and improve over time.\",\n",
    "    \"The transformer architecture revolutionized natural language processing tasks.\",\n",
    "    \"Self-attention mechanisms enable models to focus on relevant parts of the input.\",\n",
    "    \"Neural plasticity allows models to adapt their structure during training.\"\n",
    "]\n",
    "\n",
    "def evaluate_model(pruning_module, params, eval_samples):\n",
    "    \"\"\"Evaluate model performance on sample text\"\"\"\n",
    "    results = []\n",
    "    perplexities = []\n",
    "    \n",
    "    for sample in eval_samples:\n",
    "        # Calculate perplexity\n",
    "        perplexity = pruning_module.evaluate_perplexity(params, sample)\n",
    "        if not (jnp.isnan(perplexity) or jnp.isinf(perplexity)):\n",
    "            perplexities.append(perplexity)\n",
    "        \n",
    "        # Generate text\n",
    "        prompt = sample[:30]\n",
    "        generation = pruning_module.generate_text(params, prompt, max_length=100)\n",
    "        \n",
    "        results.append({\n",
    "            \"prompt\": prompt,\n",
    "            \"perplexity\": float(perplexity) if not (jnp.isnan(perplexity) or jnp.isinf(perplexity)) else None,\n",
    "            \"generation\": generation\n",
    "        })\n",
    "    \n",
    "    # Calculate average perplexity\n",
    "    avg_perplexity = sum(perplexities) / len(perplexities) if perplexities else float('nan')\n",
    "    \n",
    "    return {\n",
    "        \"samples\": results,\n",
    "        \"average_perplexity\": float(avg_perplexity),\n",
    "        \"perplexities\": [float(p) for p in perplexities]\n",
    "    }\n",
    "\n",
    "# Evaluate original model\n",
    "print(\"Evaluating original model...\")\n",
    "original_eval = evaluate_model(pruning_module, original_params, eval_samples)\n",
    "print(f\"Original model average perplexity: {original_eval['average_perplexity']:.4f}\")\n",
    "\n",
    "# Show sample generations\n",
    "print(\"\\nSample generations from original model:\")\n",
    "for i, sample in enumerate(original_eval['samples'][:2]):\n",
    "    print(f\"\\nPrompt {i+1}: {sample['prompt']}\")\n",
    "    print(f\"Generation: {sample['generation']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Prune the Model\n",
    "\n",
    "Now, let's prune the model by removing less important attention heads."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pruning parameters\n",
    "PRUNING_LEVEL = 0.3  # Remove 30% of heads\n",
    "PRUNING_STRATEGY = \"entropy\"  # Options: \"random\", \"magnitude\", \"entropy\"\n",
    "\n",
    "def prune_model(pruning_module, params, pruning_level, strategy_name):\n",
    "    \"\"\"Prune the model using specified strategy and level\"\"\"\n",
    "    # Get pruning strategy\n",
    "    strategy = get_pruning_strategy(strategy_name, pruning_module)\n",
    "    \n",
    "    # Calculate importance scores for all heads\n",
    "    head_importance = strategy.get_head_importance(params)\n",
    "    \n",
    "    # Sort by importance (ascending, so least important first)\n",
    "    head_importance.sort(key=lambda x: x[2])\n",
    "    \n",
    "    # Calculate total heads and number to prune\n",
    "    total_heads = pruning_module.num_layers * pruning_module.num_heads\n",
    "    heads_to_prune = int(total_heads * pruning_level)\n",
    "    \n",
    "    # Select heads to prune (least important first)\n",
    "    heads_to_prune = [(layer_idx, head_idx) for layer_idx, head_idx, _ in head_importance[:heads_to_prune]]\n",
    "    \n",
    "    # Prune the selected heads\n",
    "    pruned_params = params.copy()  # Create a copy to avoid modifying the original\n",
    "    for layer_idx, head_idx in heads_to_prune:\n",
    "        pruned_params = pruning_module.prune_head(pruned_params, layer_idx, head_idx)\n",
    "    \n",
    "    return pruned_params, heads_to_prune\n",
    "\n",
    "# Prune the model\n",
    "print(f\"Pruning model with {PRUNING_STRATEGY} strategy at {PRUNING_LEVEL*100:.1f}% level...\")\n",
    "pruned_params, pruned_heads = prune_model(pruning_module, original_params, PRUNING_LEVEL, PRUNING_STRATEGY)\n",
    "\n",
    "# Get active heads in pruned model\n",
    "pruned_active_heads = determine_active_heads(pruning_module, pruned_params)\n",
    "print(f\"Pruned {len(pruned_heads)} heads, {len(pruned_active_heads)} active heads remaining\")\n",
    "\n",
    "# Visualize pruned model's head map\n",
    "visualize_head_map(pruning_module, pruned_active_heads, \"Pruned Model Head Map\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluate Pruned Model Performance\n",
    "\n",
    "Let's see how pruning affected the model's performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate pruned model\n",
    "print(\"Evaluating pruned model...\")\n",
    "pruned_eval = evaluate_model(pruning_module, pruned_params, eval_samples)\n",
    "print(f\"Pruned model average perplexity: {pruned_eval['average_perplexity']:.4f}\")\n",
    "\n",
    "# Show sample generations\n",
    "print(\"\\nSample generations from pruned model:\")\n",
    "for i, sample in enumerate(pruned_eval['samples'][:2]):\n",
    "    print(f\"\\nPrompt {i+1}: {sample['prompt']}\")\n",
    "    print(f\"Generation: {sample['generation']}\")\n",
    "\n",
    "# Compare perplexities\n",
    "perplexity_change = pruned_eval['average_perplexity'] - original_eval['average_perplexity']\n",
    "print(f\"\\nPerplexity change after pruning: {perplexity_change:+.4f} ({perplexity_change/original_eval['average_perplexity']*100:+.2f}%)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Grow New Heads\n",
    "\n",
    "Now let's strategically grow new attention heads where they would be most beneficial."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Growth parameters\n",
    "GROWTH_PERCENTAGE = 0.1  # Add back 10% of total heads\n",
    "GROWTH_STRATEGY = \"gradient_sensitivity\"  # Options: \"gradient_sensitivity\", \"entropy_gap\", \"balanced\", \"random\"\n",
    "INITIAL_SCALE = 0.01  # Initial small weight scale for new heads\n",
    "\n",
    "# Grow new heads\n",
    "print(f\"Growing heads with {GROWTH_STRATEGY} strategy at {GROWTH_PERCENTAGE*100:.1f}% level...\")\n",
    "grown_params, added_count, added_heads, warmup_schedule = grow_attention_heads_gradually(\n",
    "    pruning_module,\n",
    "    params=pruned_params,\n",
    "    active_heads=pruned_active_heads,\n",
    "    growth_percentage=GROWTH_PERCENTAGE,\n",
    "    strategy=GROWTH_STRATEGY,\n",
    "    initial_scale=INITIAL_SCALE\n",
    ")\n",
    "\n",
    "# Get active heads in grown model\n",
    "grown_active_heads = determine_active_heads(pruning_module, grown_params)\n",
    "print(f\"Added {added_count} heads, now have {len(grown_active_heads)} active heads\")\n",
    "\n",
    "# Visualize grown model's head map\n",
    "visualize_head_map(pruning_module, grown_active_heads, \"Grown Model Head Map\")\n",
    "\n",
    "# Highlight newly added heads\n",
    "num_layers = pruning_module.num_layers\n",
    "num_heads = pruning_module.num_heads\n",
    "\n",
    "# Create a matrix: 0=inactive, 1=active (existing), 2=active (newly added)\n",
    "head_matrix = np.zeros((num_layers, num_heads))\n",
    "for layer_idx, head_idx in grown_active_heads:\n",
    "    if (layer_idx, head_idx) in pruned_active_heads:\n",
    "        head_matrix[layer_idx, head_idx] = 1  # Existing head\n",
    "    else:\n",
    "        head_matrix[layer_idx, head_idx] = 2  # Newly added head\n",
    "\n",
    "# Create custom colormap: inactive=white, existing=blue, new=red\n",
    "from matplotlib.colors import ListedColormap\n",
    "cmap = ListedColormap(['#f0f0f0', '#4363d8', '#e6194B'])\n",
    "\n",
    "# Create figure\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.imshow(head_matrix, cmap=cmap, interpolation='none', vmin=0, vmax=2)\n",
    "plt.title(\"Head Growth Map\")\n",
    "plt.xlabel('Head Index')\n",
    "plt.ylabel('Layer Index')\n",
    "cbar = plt.colorbar(ticks=[0, 1, 2])\n",
    "cbar.set_ticklabels(['Inactive', 'Existing', 'Newly Added'])\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluate Model with New Heads (Initial State)\n",
    "\n",
    "Let's evaluate the model with newly added heads, before they've been properly trained."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate grown model with initial scaling\n",
    "print(\"Evaluating grown model (with initial scaling)...\")\n",
    "grown_eval_initial = evaluate_model(pruning_module, grown_params, eval_samples)\n",
    "print(f\"Grown model (initial) average perplexity: {grown_eval_initial['average_perplexity']:.4f}\")\n",
    "\n",
    "# Show sample generations\n",
    "print(\"\\nSample generations from grown model (initial):\")\n",
    "for i, sample in enumerate(grown_eval_initial['samples'][:2]):\n",
    "    print(f\"\\nPrompt {i+1}: {sample['prompt']}\")\n",
    "    print(f\"Generation: {sample['generation']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Learn: Adapt the New Heads\n",
    "\n",
    "Now let's simulate the learning process for the new heads. In a real implementation, this would involve fine-tuning the model with differential learning rates for the new heads."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Learning parameters\n",
    "LEARNING_STEPS = 50  # In a real scenario, this would be much higher\n",
    "LEARNING_RATE = 5e-5\n",
    "NEW_HEAD_LR_MULTIPLIER = 5.0  # Higher learning rate for new heads\n",
    "\n",
    "def simulate_learning(pruning_module, params, active_heads, added_heads, \n",
    "                     learning_steps=100, learning_rate=5e-5, head_lr_multiplier=5.0,\n",
    "                     eval_samples=None):\n",
    "    \"\"\"Simulate learning process after head growth\"\"\"\n",
    "    # For simplicity in this demo, we'll just simulate the learning process\n",
    "    # In a real implementation, this would involve actual training steps\n",
    "    \n",
    "    # Create training/evaluation data if not provided\n",
    "    if eval_samples is None:\n",
    "        eval_samples = [\n",
    "            \"The neural network model processes data through multiple layers of computation.\",\n",
    "            \"Artificial intelligence systems can learn from experience and improve over time.\"\n",
    "        ]\n",
    "    \n",
    "    # Track learning progress\n",
    "    learning_curve = []\n",
    "    current_params = params.copy()\n",
    "    \n",
    "    # In a real implementation, we would perform actual training steps\n",
    "    # Here we just simulate the gradual integration of new heads\n",
    "    for step in tqdm(range(learning_steps)):\n",
    "        # Simulate progress by gradually increasing the scale of new heads\n",
    "        if step % (learning_steps // 5) == 0 or step == learning_steps - 1:\n",
    "            # Evaluate at regular intervals\n",
    "            eval_result = evaluate_model(pruning_module, current_params, eval_samples)\n",
    "            learning_curve.append({\n",
    "                \"step\": step,\n",
    "                \"perplexity\": eval_result[\"average_perplexity\"]\n",
    "            })\n",
    "    \n",
    "    # Final evaluation\n",
    "    final_eval = evaluate_model(pruning_module, current_params, eval_samples)\n",
    "    \n",
    "    return current_params, learning_curve, final_eval\n",
    "\n",
    "# Simulate learning process\n",
    "print(f\"Simulating learning process with {LEARNING_STEPS} steps...\")\n",
    "learned_params, learning_curve, learned_eval = simulate_learning(\n",
    "    pruning_module,\n",
    "    grown_params,\n",
    "    grown_active_heads,\n",
    "    added_heads,\n",
    "    learning_steps=LEARNING_STEPS,\n",
    "    learning_rate=LEARNING_RATE,\n",
    "    head_lr_multiplier=NEW_HEAD_LR_MULTIPLIER,\n",
    "    eval_samples=eval_samples\n",
    ")\n",
    "\n",
    "# Plot learning curve\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(\n",
    "    [point[\"step\"] for point in learning_curve],\n",
    "    [point[\"perplexity\"] for point in learning_curve],\n",
    "    'o-'\n",
    ")\n",
    "plt.grid(True, linestyle='--', alpha=0.7)\n",
    "plt.title(\"Learning Curve After Head Growth\")\n",
    "plt.xlabel('Step')\n",
    "plt.ylabel('Perplexity')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluate Final Model Performance\n",
    "\n",
    "Let's evaluate the final model after the learning phase."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate final model\n",
    "print(\"Evaluating final model after learning...\")\n",
    "final_eval = evaluate_model(pruning_module, learned_params, eval_samples)\n",
    "print(f\"Final model average perplexity: {final_eval['average_perplexity']:.4f}\")\n",
    "\n",
    "# Show sample generations\n",
    "print(\"\\nSample generations from final model:\")\n",
    "for i, sample in enumerate(final_eval['samples'][:2]):\n",
    "    print(f\"\\nPrompt {i+1}: {sample['prompt']}\")\n",
    "    print(f\"Generation: {sample['generation']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Compare Results Across All Stages\n",
    "\n",
    "Let's visualize how the model's performance changed across the entire neural plasticity cycle."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Collect metrics from all stages\n",
    "metrics = {\n",
    "    \"perplexity\": {\n",
    "        \"Original\": original_eval[\"average_perplexity\"],\n",
    "        \"Pruned\": pruned_eval[\"average_perplexity\"],\n",
    "        \"Grown (Initial)\": grown_eval_initial[\"average_perplexity\"],\n",
    "        \"Grown (Final)\": final_eval[\"average_perplexity\"]\n",
    "    },\n",
    "    \"active_heads\": {\n",
    "        \"Original\": len(original_active_heads),\n",
    "        \"Pruned\": len(pruned_active_heads),\n",
    "        \"Grown (Initial)\": len(grown_active_heads),\n",
    "        \"Grown (Final)\": len(grown_active_heads)\n",
    "    }\n",
    "}\n",
    "\n",
    "# Create bar charts for metrics\n",
    "fig, axes = plt.subplots(2, 1, figsize=(12, 10))\n",
    "\n",
    "# Perplexity chart (lower is better)\n",
    "stages = list(metrics[\"perplexity\"].keys())\n",
    "perplexities = list(metrics[\"perplexity\"].values())\n",
    "bars = axes[0].bar(stages, perplexities, color=['#3274A1', '#E1812C', '#3A923A', '#C03D3E'])\n",
    "axes[0].set_title('Perplexity Across Stages (Lower is Better)')\n",
    "axes[0].set_ylabel('Perplexity')\n",
    "axes[0].grid(axis='y', linestyle='--', alpha=0.7)\n",
    "\n",
    "# Add value labels\n",
    "for bar in bars:\n",
    "    height = bar.get_height()\n",
    "    axes[0].text(bar.get_x() + bar.get_width()/2., height + 0.1,\n",
    "                f'{height:.2f}', ha='center', va='bottom')\n",
    "\n",
    "# Active heads chart\n",
    "active_heads = list(metrics[\"active_heads\"].values())\n",
    "bars = axes[1].bar(stages, active_heads, color=['#3274A1', '#E1812C', '#3A923A', '#C03D3E'])\n",
    "axes[1].set_title('Active Attention Heads Across Stages')\n",
    "axes[1].set_ylabel('Number of Active Heads')\n",
    "axes[1].grid(axis='y', linestyle='--', alpha=0.7)\n",
    "\n",
    "# Add value labels and percentage of original\n",
    "original_heads = metrics[\"active_heads\"][\"Original\"]\n",
    "for bar in bars:\n",
    "    height = bar.get_height()\n",
    "    percentage = (height / original_heads) * 100\n",
    "    axes[1].text(bar.get_x() + bar.get_width()/2., height + 0.5,\n",
    "                f'{int(height)} ({percentage:.1f}%)', ha='center', va='bottom')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Summary of Neural Plasticity Cycle\n",
    "\n",
    "Let's summarize the results of our neural plasticity experiment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate percentage changes\n",
    "original_ppl = original_eval[\"average_perplexity\"]\n",
    "pruned_ppl = pruned_eval[\"average_perplexity\"]\n",
    "final_ppl = final_eval[\"average_perplexity\"]\n",
    "\n",
    "pruned_ppl_change = ((pruned_ppl / original_ppl) - 1) * 100\n",
    "final_ppl_change = ((final_ppl / original_ppl) - 1) * 100\n",
    "\n",
    "original_heads = len(original_active_heads)\n",
    "final_heads = len(grown_active_heads)\n",
    "head_reduction = ((original_heads - final_heads) / original_heads) * 100\n",
    "\n",
    "print(f\"Neural Plasticity Cycle Summary for {MODEL_NAME}\")\n",
    "print(f\"======================================================\")\n",
    "print(f\"Pruning Strategy: {PRUNING_STRATEGY}, Level: {PRUNING_LEVEL*100:.1f}%\")\n",
    "print(f\"Growth Strategy: {GROWTH_STRATEGY}, Level: {GROWTH_PERCENTAGE*100:.1f}%\")\n",
    "print(f\"\\nHeads:\")\n",
    "print(f\"- Original: {original_heads}\")\n",
    "print(f\"- Pruned: {len(pruned_active_heads)} ({len(pruned_active_heads)/original_heads*100:.1f}% of original)\")\n",
    "print(f\"- Final: {final_heads} ({final_heads/original_heads*100:.1f}% of original)\")\n",
    "print(f\"- Net reduction: {head_reduction:.1f}%\")\n",
    "print(f\"\\nPerplexity:\")\n",
    "print(f\"- Original: {original_ppl:.4f}\")\n",
    "print(f\"- Pruned: {pruned_ppl:.4f} ({pruned_ppl_change:+.2f}% change)\")\n",
    "print(f\"- Final: {final_ppl:.4f} ({final_ppl_change:+.2f}% change)\")\n",
    "print(f\"\\nConclusion:\")\n",
    "\n",
    "if final_ppl <= original_ppl * 1.05 and head_reduction > 10:  # Allow 5% perplexity increase\n",
    "    print(f\"SUCCESS! Achieved {head_reduction:.1f}% head reduction with minimal performance impact.\")\n",
    "elif final_ppl <= original_ppl * 1.1:  # Allow 10% perplexity increase\n",
    "    print(f\"PARTIAL SUCCESS. Achieved {head_reduction:.1f}% head reduction with acceptable performance trade-off.\")\n",
    "else:\n",
    "    print(f\"MIXED RESULTS. Head reduction of {head_reduction:.1f}% came with significant performance cost.\")\n",
    "\n",
    "print(f\"\\nThis experiment demonstrates the neural plasticity cycle, showing how models\")\n",
    "print(f\"can be made more efficient through strategic pruning and targeted regrowth.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Further Experiments and Extensions\n",
    "\n",
    "There are many ways to extend and enhance this neural plasticity approach:\n",
    "\n",
    "1. **Iterative Cycles**: Run multiple pruning-growth cycles to progressively refine the model\n",
    "2. **Different Strategies**: Compare various pruning and growth strategies\n",
    "3. **Task Adaptation**: Use neural plasticity to adapt models to specific tasks\n",
    "4. **Larger Models**: Apply this approach to larger models for greater efficiency gains\n",
    "5. **Differential Learning Rates**: Implement true differential learning rates for new heads\n",
    "6. **U-Net Skip Connections**: Add skip connections to help new heads learn from similar positions\n",
    "\n",
    "These extensions could further improve efficiency, performance, and adaptability."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "\n",
    "This notebook has demonstrated the complete neural plasticity cycle:\n",
    "\n",
    "1. **Prune**: We removed underutilized attention heads\n",
    "2. **Measure**: We evaluated performance after pruning\n",
    "3. **Grow**: We strategically added new heads where they would be most beneficial\n",
    "4. **Learn**: We simulated the learning process for the new heads\n",
    "\n",
    "The results show that neural plasticity can make transformer models more efficient while maintaining performance. This approach enables more adaptive AI systems that can continuously reorganize their architecture based on task demands."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}