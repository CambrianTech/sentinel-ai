{
    "cells": [
      {
        "cell_type": "markdown",
        "source": [
          "# ðŸ’¡ Low Resource Adaptivity\n",
          "\n",
          "This notebook demonstrates that the Adaptive Transformer model self-prunes and continues to function under constrained compute environments (e.g., Colab T4 or CPU)."
        ]
      },
      {
        "cell_type": "code",
        "source": [
          "!pip install transformers datasets matplotlib torch"
        ]
      },
      {
        "cell_type": "code",
        "source": [
          "import torch\n",
          "import matplotlib.pyplot as plt\n",
          "from transformers import AutoTokenizer\n",
          "from models.loaders.loader import load_adaptive_model, load_baseline_model\n",
          "from data_modules.dataset_loader import load_and_tokenize_dataset\n",
          "from utils.training import count_active_heads, compute_loss\n",
          "from torch.optim import AdamW\n",
          "import gc"
        ]
      },
      {
        "cell_type": "code",
        "source": [
          "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
          "print(f\"ðŸ§  Running on: {device}\")"
        ]
      },
      {
        "cell_type": "code",
        "source": [
          "model_name = \"distilgpt2\"\n",
          "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
          "baseline = load_baseline_model(model_name, device)\n",
          "adaptive = load_adaptive_model(model_name, baseline, device)\n",
          "adaptive.train()"
        ]
      },
      {
        "cell_type": "code",
        "source": [
          "train_ids, _ = load_and_tokenize_dataset(model_name=model_name, dataset_name=\"tiny_shakespeare\")\n",
          "optimizer = AdamW(adaptive.parameters(), lr=5e-5)\n",
          "inputs = torch.tensor(train_ids[:8]).to(device)"
        ]
      },
      {
        "cell_type": "markdown",
        "source": [
          "## ðŸš¦ Adaptive Behavior Under Limited Resources"
        ]
      },
      {
        "cell_type": "code",
        "source": [
          "active_heads_history = []\n",
          "losses = []\n",
          "\n",
          "for step in range(20):\n",
          "    optimizer.zero_grad()\n",
          "    logits = adaptive(inputs)\n",
          "    loss = compute_loss(logits, inputs)\n",
          "    loss.backward()\n",
          "    optimizer.step()\n",
          "\n",
          "    active_heads = count_active_heads(adaptive)\n",
          "    active_heads_history.append(active_heads)\n",
          "    losses.append(loss.item())\n",
          "    print(f\"Step {step}: Loss = {loss.item():.4f}, Active Heads = {active_heads}\")\n",
          "\n",
          "    # Simulate pruning under constrained setting\n",
          "    if step % 5 == 0:\n",
          "        for block in adaptive.blocks:\n",
          "            attn = block['attn']\n",
          "            with torch.no_grad():\n",
          "                attn.gate[attn.gate < 0.1] = 0.0\n",
          "\n",
          "gc.collect(); torch.cuda.empty_cache()"
        ]
      },
      {
        "cell_type": "markdown",
        "source": [
          "## ðŸ“ˆ Results"
        ]
      },
      {
        "cell_type": "code",
        "source": [
          "plt.figure(figsize=(12, 5))\n",
          "plt.subplot(1, 2, 1)\n",
          "plt.plot(losses, label=\"Loss\")\n",
          "plt.title(\"Loss Over Steps\")\n",
          "plt.xlabel(\"Step\"); plt.ylabel(\"Loss\"); plt.grid()\n",
          "\n",
          "plt.subplot(1, 2, 2)\n",
          "plt.plot(active_heads_history, label=\"Active Heads\", color='orange')\n",
          "plt.title(\"Active Heads vs. Training Step\")\n",
          "plt.xlabel(\"Step\"); plt.ylabel(\"Active Heads\")\n",
          "plt.grid()\n",
          "plt.tight_layout()\n",
          "plt.show()"
        ]
      }
    ],
    "metadata": {
      "kernelspec": {
        "name": "python3",
        "display_name": "Python 3",
        "language": "python"
      },
      "language_info": {
        "name": "python",
        "version": "3.10"
      }
    },
    "nbformat": 4,
    "nbformat_minor": 5
  }
  