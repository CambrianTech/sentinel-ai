{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "4ee83d30",
      "metadata": {},
      "source": [
        "# ‚úÖ Checkpoint Resumption Test\n",
        "\n",
        "This notebook demonstrates that training resumes correctly from a saved checkpoint and that controller gates, optimizer state, and training metrics continue progressing as expected."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "33fdb9cb",
      "metadata": {},
      "outputs": [],
      "source": [
        "!pip install transformers datasets"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "195b5f7e",
      "metadata": {},
      "outputs": [],
      "source": [
        "import torch\n",
        "import os\n",
        "from transformers import AutoTokenizer\n",
        "from models.loaders.loader import load_baseline_model, load_adaptive_model\n",
        "from datasets.dataset_loader import load_and_tokenize_dataset\n",
        "from utils.checkpoint import save_checkpoint, load_checkpoint\n",
        "from utils.training import compute_loss\n",
        "from torch.optim import AdamW"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "76fde9e4",
      "metadata": {},
      "outputs": [],
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model_name = \"distilgpt2\"\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
        "baseline = load_baseline_model(model_name, device)\n",
        "adaptive = load_adaptive_model(model_name, baseline, device)\n",
        "adaptive.train()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d5b0d865",
      "metadata": {},
      "outputs": [],
      "source": [
        "train_ids, _ = load_and_tokenize_dataset(model_name=model_name, dataset_name=\"tiny_shakespeare\")\n",
        "inputs = torch.tensor(train_ids[:4]).to(device)\n",
        "optimizer = AdamW(adaptive.parameters(), lr=1e-4)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "73618133",
      "metadata": {},
      "source": [
        "## ‚è∫Ô∏è Step 1: Train and Save Checkpoint"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "94a174f1",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Simple 2-step warm-up\n",
        "for step in range(2):\n",
        "    optimizer.zero_grad()\n",
        "    logits = adaptive(inputs)\n",
        "    loss = compute_loss(logits, inputs)\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "    print(f\"Step {step}, Loss: {loss.item():.4f}\")\n",
        "\n",
        "save_checkpoint(\"resumption_test.pth\", adaptive, optimizer, {}, epoch=0, step=2)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "430d57fd",
      "metadata": {},
      "source": [
        "## üîÅ Step 2: Reload Model and Resume"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b5b08673",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Create a fresh model and optimizer to test resumption\n",
        "baseline = load_baseline_model(model_name, device)\n",
        "resumed = load_adaptive_model(model_name, baseline, device)\n",
        "resumed.train()\n",
        "opt2 = AdamW(resumed.parameters(), lr=1e-4)\n",
        "checkpoint_data = load_checkpoint(\"resumption_test.pth\", resumed, opt2)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0dedf0ef",
      "metadata": {},
      "source": [
        "## ‚úÖ Step 3: Validate Training Continuation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f4cb07eb",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Resume for 2 more steps\n",
        "for step in range(2):\n",
        "    opt2.zero_grad()\n",
        "    logits = resumed(inputs)\n",
        "    loss = compute_loss(logits, inputs)\n",
        "    loss.backward()\n",
        "    opt2.step()\n",
        "    print(f\"[Resumed] Step {step + checkpoint_data['step']}, Loss: {loss.item():.4f}\")"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.10"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
