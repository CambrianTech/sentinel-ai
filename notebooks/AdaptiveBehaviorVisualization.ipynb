{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# \ud83d\udcca Adaptive Behavior Visualization\n",
        "\n",
        "This notebook visualizes the dynamic adaptivity of attention heads during training, specifically their activation and pruning behavior."
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install transformers datasets matplotlib seaborn"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from models.adaptive_transformer import AdaptiveTransformerModel\n",
        "from controller.controller_ann import ANNController\n",
        "from loader import load_adaptive_model, load_baseline_model\n",
        "from data_modules.dataset_loader import load_and_tokenize_dataset\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
      ],
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "## \u2699\ufe0f Configuration"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "model_name = 'distilgpt2'\n",
        "dataset_name = 'tiny_shakespeare'\n",
        "train_data, val_data = load_and_tokenize_dataset(model_name, dataset_name)"
      ],
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "## \ud83e\udde0 Load Model"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "baseline_model = load_baseline_model(model_name, device)\n",
        "adaptive_model = load_adaptive_model(model_name, baseline_model, device)\n",
        "controller = ANNController(num_layers=adaptive_model.config.n_layer, num_heads=adaptive_model.config.n_head)\n",
        "adaptive_model.controller = controller.to(device)"
      ],
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "## \ud83d\udd04 Visualize Adaptive Gates (Before Training)"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "def plot_gates(controller, title='Head Activation Gates'):\n",
        "    gates = torch.sigmoid(controller.gate_logits).detach().cpu().numpy()\n",
        "    plt.figure(figsize=(12, 6))\n",
        "    sns.heatmap(gates, annot=True, cmap='viridis', vmin=0, vmax=1)\n",
        "    plt.xlabel('Heads')\n",
        "    plt.ylabel('Layers')\n",
        "    plt.title(title)\n",
        "    plt.show()\n",
        "\n",
        "plot_gates(controller, 'Initial Head Activation Gates')"
      ],
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "## \ud83d\ude80 Short Training Loop (Demo Adaptivity)"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "optimizer = torch.optim.AdamW(adaptive_model.parameters(), lr=1e-5)\n",
        "adaptive_model.train()\n",
        "\n",
        "for step in range(100):\n",
        "    inputs = torch.tensor(train_data[step % len(train_data)]).unsqueeze(0).to(device)\n",
        "    outputs = adaptive_model(inputs)\n",
        "    loss = torch.nn.functional.cross_entropy(outputs[:, :-1, :].contiguous().view(-1, outputs.size(-1)), inputs[:, 1:].contiguous().view(-1))\n",
        "    loss += controller.regularization_loss() * 1e-4\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "    optimizer.zero_grad()\n",
        "\n",
        "    if step % 25 == 0:\n",
        "        print(f\"Step {step}: Loss = {loss.item():.4f}\")\n",
        "        plot_gates(controller, f'Adaptive Gates at Step {step}')"
      ],
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "## \ud83d\udcc9 Final Adaptivity"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "plot_gates(controller, 'Final Head Activation Gates')"
      ],
      "metadata": {}
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python",
      "version": "3.x"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}