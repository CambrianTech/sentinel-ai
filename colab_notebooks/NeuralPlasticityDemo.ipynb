{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Neural Plasticity Demo: Dynamic Pruning & Regrowth (v0.0.64 (2025-04-20 02:56:19))\n",
    "\n",
    "This notebook demonstrates Sentinel AI's neural plasticity system, which allows transformer models to dynamically prune and regrow attention heads during training based on utility metrics. [ID: 2a9d6687]\n",
    "\n",
    "### Changes in v0.0.64:\n",
    "- **Further modularization with fully encapsulated plasticity cycle API**\n",
    "- Used new `run_multiple_pruning_cycles` method for continuous pruning\n",
    "- Removed redundant visualizations and print statements from notebook\n",
    "- All visualization and tracking now handled by the module API\n",
    "## What is Neural Plasticity?\n",
    "\n",
    "Neural plasticity is the ability of neural networks to adapt their structure over time through pruning (removing unused connections) and regrowth (restoring useful connections). This mimics how biological brains form efficient neural pathways.\n",
    "\n",
    "In this demo, we run a continuous plasticity process:\n",
    "1. Track the entropy and gradient patterns of each attention head\n",
    "2. Dynamically prune high-entropy, low-gradient heads (unfocused, less useful)\n",
    "3. Train the pruned model to adapt to its new structure\n",
    "4. Analyze head metrics again and potentially recover useful heads\n",
    "5. Continue this cycle multiple times to form progressively better neural structures\n",
    "6. Visualize the \"brain dynamics\" over time\n",
    "\n",
    "This allows models to form more efficient neural pathways, just like real brains during development and learning.\n",
    "\n",
    "## Environment Compatibility\n",
    "\n",
    "This notebook automatically detects your execution environment and applies the appropriate optimizations:\n",
    "\n",
    "- **Colab:** Uses GPU acceleration when available for maximum performance\n",
    "- **Apple Silicon:** Applies safeguards against BLAS/libtorch crashes that commonly occur on M1/M2/M3 Macs\n",
    "- **Standard Hardware:** Operates normally with GPU acceleration when available\n",
    "\n",
    "No manual configuration is required - just run the cells and the notebook will optimize for your environment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e47f8d03",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check and install system dependencies if needed\n",
    "!apt-get update -qq > /dev/null\n",
    "!apt-get install -qq libopenblas-dev > /dev/null  # For better performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install required packages\n",
    "!pip install -q torch transformers datasets matplotlib seaborn\n",
    "\n",
    "# Clone the Sentinel AI repository\n",
    "!git clone -b feature/implement-adaptive-plasticity https://github.com/CambrianTech/sentinel-ai.git\n",
    "%cd sentinel-ai\n",
    "\n",
    "# Add repository to path\n",
    "import sys\n",
    "sys.path.append('.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Configure the Experiment\n",
    "\n",
    "Let's set up our configuration for the neural plasticity experiment"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configure experiment\n",
    "MODEL_NAME = \"distilgpt2\"  # Small GPT-2 model for faster demonstration\n",
    "DATASET = \"wikitext\"\n",
    "DATASET_CONFIG = \"wikitext-2-raw-v1\"\n",
    "MAX_LENGTH = 128\n",
    "BATCH_SIZE = 4\n",
    "NUM_CYCLES = 3           # Number of pruning cycles for continuous plasticity\n",
    "LEARNING_RATE = 5e-5\n",
    "WARMUP_STEPS = 100\n",
    "PRUNING_STRATEGY = \"combined\"  # Options: \"entropy\", \"gradient\", \"random\", \"combined\"\n",
    "PRUNING_LEVEL = 0.15     # Target percentage of heads to prune in each cycle\n",
    "OUTPUT_DIR = \"neural_plasticity_output\"  # Directory for saving results\n",
    "TRAINING_STEPS_PER_CYCLE = 100  # Number of training steps per pruning cycle\n",
    "\n",
    "# Customize visualization options\n",
    "SAVE_VISUALIZATIONS = True\n",
    "VERBOSE = True\n",
    "\n",
    "# Define inference prompts for consistent testing\n",
    "INFERENCE_PROMPTS = {\n",
    "    \"story\": \"Once upon a time\",\n",
    "    \"ai\": \"The future of artificial intelligence\",\n",
    "    \"space\": \"In a distant galaxy\",\n",
    "    \"science\": \"Scientists recently discovered\"\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Model and Dataset\n",
    "\n",
    "Now we'll load the model and prepare the dataset for training"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "from datetime import datetime\n",
    "from utils.neural_plasticity.experiment import NeuralPlasticityExperiment\n",
    "from utils.neural_plasticity.visualization import create_pruning_state_heatmap\n",
    "\n",
    "# Create timestamp for output directory\n",
    "timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "output_path = os.path.join(OUTPUT_DIR, f\"experiment_{timestamp}\")\n",
    "\n",
    "# Create the experiment instance\n",
    "experiment = NeuralPlasticityExperiment(\n",
    "    model_name=MODEL_NAME,\n",
    "    dataset=DATASET,\n",
    "    dataset_config=DATASET_CONFIG,\n",
    "    output_dir=output_path,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    max_length=MAX_LENGTH,\n",
    "    pruning_level=PRUNING_LEVEL,\n",
    "    pruning_strategy=PRUNING_STRATEGY,\n",
    "    learning_rate=LEARNING_RATE,\n",
    "    verbose=VERBOSE,\n",
    "    save_results=SAVE_VISUALIZATIONS\n",
    ")\n",
    "\n",
    "print(f\"Neural Plasticity Experiment v0.0.64 initialized\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define Evaluation Function\n",
    "\n",
    "Let's define a function to evaluate our model's performance"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup and baseline evaluation\n",
    "experiment.setup()\n",
    "baseline_metrics = experiment.evaluate()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run Model Warm-up\n",
    "\n",
    "Before measuring baseline performance and applying neural plasticity, we'll run a brief warm-up phase to get initial attention patterns and stabilize metrics."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run warmup phase\n",
    "warmup_results = experiment.run_warmup(\n",
    "    max_epochs=1,\n",
    "    patience=15,\n",
    "    min_steps=50,\n",
    "    max_steps=150\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Analyze Attention Patterns\n",
    "\n",
    "Now that we've run the warm-up phase, let's analyze the attention patterns to identify heads for potential pruning. The experiment class will calculate important metrics for each attention head."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze attention patterns\n",
    "attention_analysis = experiment.analyze_attention()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Run Continuous Neural Plasticity Cycles\n",
    "\n",
    "A key feature of neural plasticity is that it's a continuous, ongoing process. Rather than pruning just once, we'll run multiple cycles of pruning and adaptation to allow the model to continuously evolve its structure based on learning needs."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run multiple pruning cycles to simulate continuous neural plasticity\n",
    "# This uses the modular API to handle all tracking and visualization automatically\n",
    "multi_cycle_results = experiment.run_multiple_pruning_cycles(\n",
    "    num_cycles=NUM_CYCLES,\n",
    "    training_steps=TRAINING_STEPS_PER_CYCLE\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Evaluate Continuous Plasticity Results\n",
    "\n",
    "After running multiple cycles of neural plasticity, we can analyze the evolution metrics that were automatically tracked by the experiment.\n",
    "\n",
    "The `run_multiple_pruning_cycles` method handles the tracking of metrics across cycles, including perplexity, number of pruned heads, loss, and model sparsity. The method also handles creating visualizations showing the evolution of the model structure."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate final model after multiple pruning cycles\n",
    "final_metrics = experiment.evaluate()\n",
    "\n",
    "# The evolution plot was automatically generated by run_multiple_pruning_cycles\n",
    "# We can access cycle metrics directly from the results\n",
    "cycle_metrics = multi_cycle_results['cycle_metrics']\n",
    "\n",
    "# Generate text examples to see how the model performs after continuous plasticity\n",
    "generated_texts = experiment.generate_examples(prompts=INFERENCE_PROMPTS, max_length=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Neural Plasticity Evolution Dashboard\n",
    "\n",
    "Let's create a comprehensive visualization of how the model evolved through multiple plasticity cycles:"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create metrics dashboard and save results\n",
    "experiment.visualize_metrics_dashboard()\n",
    "\n",
    "# Save model and metadata if enabled\n",
    "if SAVE_VISUALIZATIONS:\n",
    "    experiment.save_model()\n",
    "    experiment.save_metadata()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "outputs": [],
   "source": [
    "## One-Shot Experiment\n",
    "\n",
    "The `NeuralPlasticityExperiment` class provides a way to run the entire pipeline in a single call using the `run_full_experiment()` method. This method now uses the modular `run_multiple_pruning_cycles` internally to provide consistent results with the step-by-step approach above.\n",
    "\n",
    "This is particularly useful for training longer experiments on Colab where you might want to let it run overnight without interactive monitoring each step."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "outputs": [],
   "source": [
    "# One-shot experiment with multiple plasticity cycles (uncomment to run)\n",
    "\"\"\"\n",
    "# Create experiment with different output directory\n",
    "oneshot_timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "oneshot_output_path = os.path.join(OUTPUT_DIR, f\"oneshot_{oneshot_timestamp}\")\n",
    "\n",
    "# Create and run one-shot experiment\n",
    "oneshot_experiment = NeuralPlasticityExperiment(\n",
    "    model_name=MODEL_NAME,\n",
    "    dataset=DATASET, \n",
    "    dataset_config=DATASET_CONFIG,\n",
    "    output_dir=oneshot_output_path,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    max_length=MAX_LENGTH,\n",
    "    pruning_level=PRUNING_LEVEL,\n",
    "    pruning_strategy=PRUNING_STRATEGY,\n",
    "    learning_rate=LEARNING_RATE,\n",
    "    verbose=VERBOSE,\n",
    "    save_results=SAVE_VISUALIZATIONS\n",
    ")\n",
    "\n",
    "# Run full experiment pipeline with multiple plasticity cycles\n",
    "# This internally uses run_multiple_pruning_cycles for modular consistency\n",
    "results = oneshot_experiment.run_full_experiment(\n",
    "    warmup_epochs=1,\n",
    "    pruning_cycles=NUM_CYCLES,\n",
    "    training_steps=TRAINING_STEPS_PER_CYCLE\n",
    ")\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Compare Pruning Strategies\n",
    "\n",
    "The NeuralPlasticityExperiment class also allows you to compare different pruning strategies and levels. This code is commented out by default as it can take a while to run."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Strategy comparison (uncomment to run)\n",
    "\"\"\"\n",
    "# Create experiment for strategy comparison\n",
    "comparison_timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "comparison_output_path = os.path.join(OUTPUT_DIR, f\"comparison_{comparison_timestamp}\")\n",
    "\n",
    "# Create and setup experiment\n",
    "comparison_experiment = NeuralPlasticityExperiment(\n",
    "    model_name=MODEL_NAME,\n",
    "    dataset=DATASET,\n",
    "    dataset_config=DATASET_CONFIG,\n",
    "    output_dir=comparison_output_path,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    max_length=MAX_LENGTH,\n",
    "    pruning_level=0.1,\n",
    "    pruning_strategy=\"combined\",\n",
    "    learning_rate=LEARNING_RATE,\n",
    "    verbose=VERBOSE,\n",
    "    save_results=True\n",
    ")\n",
    "\n",
    "# Setup and run warmup\n",
    "comparison_experiment.setup()\n",
    "comparison_experiment.run_warmup(max_epochs=1)\n",
    "\n",
    "# Run comparison\n",
    "comparison_results = comparison_experiment.compare_pruning_strategies(\n",
    "    strategies=[\"entropy\", \"gradient\", \"random\", \"combined\"],\n",
    "    pruning_levels=[0.1, 0.2, 0.3],\n",
    "    cycles=1,\n",
    "    training_steps=100\n",
    ")\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Conclusion\n",
    "\n",
    "In this notebook, we demonstrated Sentinel AI's neural plasticity system using the fully modular `NeuralPlasticityExperiment` class.\n",
    "\n",
    "Key findings:\n",
    "1. The system successfully implements **continuous neural plasticity** through multiple pruning cycles\n",
    "2. Each cycle improves model structure by pruning less useful heads and potentially recovering valuable ones\n",
    "3. The progressive refinement mimics how biological brains optimize neural pathways\n",
    "4. Pruned models maintain or improve performance with fewer active heads\n",
    "5. The entire pipeline works consistently across different environments\n",
    "\n",
    "### Benefits of the Modular Architecture\n",
    "\n",
    "The modular architecture in v0.0.64 provides significant advantages:\n",
    "\n",
    "1. **Fully Encapsulated Functionality**: All plasticity operations are encapsulated in API methods\n",
    "2. **No Code Duplication**: The same code paths handle both interactive steps and one-shot runs\n",
    "3. **Presentation-Logic Separation**: Notebooks focus on presentation while modules handle logic\n",
    "4. **Cross-Platform Compatibility**: The same code works reliably across standard CPUs, GPUs, and Apple Silicon\n",
    "5. **Environment-Aware Visualization**: Automatically displays or saves visualizations based on execution context\n",
    "6. **Continuous Plasticity Loop**: Multiple pruning cycles with comprehensive tracking in a single call\n",
    "7. **Reproducibility**: Standardized experiments with consistent outputs\n",
    "\n",
    "This approach mimics biological neural plasticity, where brains continuously form efficient neural pathways by pruning unused connections and strengthening useful ones over time."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
