#!/usr/bin/env python
# Fix Neural Plasticity Demo notebook using proper nbformat

import nbformat
import os
from datetime import datetime

# Path to the notebook
notebook_path = "colab_notebooks/NeuralPlasticityDemo.ipynb"

# Read the notebook
print(f"Reading notebook: {notebook_path}")
nb = nbformat.read(notebook_path, as_version=4)

# Current timestamp
timestamp = datetime.now().strftime("%Y-%m-%d %H:%M:%S")
version = "v0.0.64"
version_string = f"{version} ({timestamp})"

# Update cells
changes_made = False

# Update the title cell (cell 0)
if len(nb.cells) > 0 and nb.cells[0].cell_type == "markdown":
    title_cell = nb.cells[0].source
    if "Neural Plasticity Demo: Dynamic Pruning & Regrowth" in title_cell:
        # Replace the version and timestamp in the title
        lines = title_cell.split('\n')
        for i, line in enumerate(lines):
            if "Neural Plasticity Demo: Dynamic Pruning & Regrowth" in line:
                lines[i] = f"# Neural Plasticity Demo: Dynamic Pruning & Regrowth ({version_string})"
                break
        
        # Update changes section
        changes_section = """
### Changes in v0.0.64:
- **Further modularization with fully encapsulated plasticity cycle API**
- Used new `run_multiple_pruning_cycles` method for continuous pruning
- Removed redundant visualizations and print statements from notebook
- All visualization and tracking now handled by the module API
"""
        
        # Find the changes section and replace it
        for i, line in enumerate(lines):
            if "### Changes in" in line:
                # Replace this line and subsequent lines until we hit a section that doesn't start with -
                end_idx = i + 1
                while end_idx < len(lines) and (lines[end_idx].strip().startswith('-') or not lines[end_idx].strip()):
                    end_idx += 1
                
                # Replace the changes section
                lines[i:end_idx] = changes_section.strip().split('\n')
                break
        
        nb.cells[0].source = '\n'.join(lines)
        changes_made = True
        print("Updated title cell with new version information")

# Update cell with experiment initialization (cell 6)
if len(nb.cells) > 6 and nb.cells[6].cell_type == "code":
    init_cell = nb.cells[6].source
    if "experiment = NeuralPlasticityExperiment" in init_cell:
        # Ensure version print is updated
        lines = init_cell.split('\n')
        version_print_found = False
        for i, line in enumerate(lines):
            if "print(f\"Neural Plasticity Experiment" in line:
                lines[i] = f'print(f"Neural Plasticity Experiment {version} initialized")'
                version_print_found = True
                break
        
        # If version print not found, add it
        if not version_print_found:
            lines.append(f'print(f"Neural Plasticity Experiment {version} initialized")')
        
        nb.cells[6].source = '\n'.join(lines)
        changes_made = True
        print("Updated experiment initialization cell")

# Update the multiple cycles cell (cell 14)
if len(nb.cells) > 14 and nb.cells[14].cell_type == "code":
    cycle_cell_content = """# Run multiple pruning cycles to simulate continuous neural plasticity
# This uses the modular API to handle all tracking and visualization automatically
multi_cycle_results = experiment.run_multiple_pruning_cycles(
    num_cycles=NUM_CYCLES,
    training_steps=TRAINING_STEPS_PER_CYCLE
)"""
    nb.cells[14].source = cycle_cell_content
    changes_made = True
    print("Updated multiple cycles cell")

# Update evaluation explanation (cell 15)
if len(nb.cells) > 15 and nb.cells[15].cell_type == "markdown":
    eval_explain = """## Evaluate Continuous Plasticity Results

After running multiple cycles of neural plasticity, we can analyze the evolution metrics that were automatically tracked by the experiment.

The `run_multiple_pruning_cycles` method handles the tracking of metrics across cycles, including perplexity, number of pruned heads, loss, and model sparsity. The method also handles creating visualizations showing the evolution of the model structure."""
    nb.cells[15].source = eval_explain
    changes_made = True
    print("Updated evaluation explanation cell")

# Update evaluation cell (cell 16)
if len(nb.cells) > 16 and nb.cells[16].cell_type == "code":
    eval_cell_content = """# Evaluate final model after multiple pruning cycles
final_metrics = experiment.evaluate()

# The evolution plot was automatically generated by run_multiple_pruning_cycles
# We can access cycle metrics directly from the results
cycle_metrics = multi_cycle_results['cycle_metrics']

# Generate text examples to see how the model performs after continuous plasticity
generated_texts = experiment.generate_examples(prompts=INFERENCE_PROMPTS, max_length=100)"""
    nb.cells[16].source = eval_cell_content
    changes_made = True
    print("Updated evaluation cell")

# Update one-shot explanation (cell 19)
if len(nb.cells) > 19 and nb.cells[19].cell_type == "markdown":
    oneshot_explain = """## One-Shot Experiment

The `NeuralPlasticityExperiment` class provides a way to run the entire pipeline in a single call using the `run_full_experiment()` method. This method now uses the modular `run_multiple_pruning_cycles` internally to provide consistent results with the step-by-step approach above.

This is particularly useful for training longer experiments on Colab where you might want to let it run overnight without interactive monitoring each step."""
    nb.cells[19].source = oneshot_explain
    changes_made = True
    print("Updated one-shot explanation cell")

# Update one-shot code cell (cell 20)
if len(nb.cells) > 20 and nb.cells[20].cell_type == "code":
    oneshot_code = """# One-shot experiment with multiple plasticity cycles (uncomment to run)
\"\"\"
# Create experiment with different output directory
oneshot_timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
oneshot_output_path = os.path.join(OUTPUT_DIR, f"oneshot_{oneshot_timestamp}")

# Create and run one-shot experiment
oneshot_experiment = NeuralPlasticityExperiment(
    model_name=MODEL_NAME,
    dataset=DATASET, 
    dataset_config=DATASET_CONFIG,
    output_dir=oneshot_output_path,
    batch_size=BATCH_SIZE,
    max_length=MAX_LENGTH,
    pruning_level=PRUNING_LEVEL,
    pruning_strategy=PRUNING_STRATEGY,
    learning_rate=LEARNING_RATE,
    verbose=VERBOSE,
    save_results=SAVE_VISUALIZATIONS
)

# Run full experiment pipeline with multiple plasticity cycles
# This internally uses run_multiple_pruning_cycles for modular consistency
results = oneshot_experiment.run_full_experiment(
    warmup_epochs=1,
    pruning_cycles=NUM_CYCLES,
    training_steps=TRAINING_STEPS_PER_CYCLE
)
\"\"\""""
    nb.cells[20].source = oneshot_code
    changes_made = True
    print("Updated one-shot code cell")

# Update conclusion cell (cell 23)
if len(nb.cells) > 23 and nb.cells[23].cell_type == "markdown":
    conclusion = """## Conclusion

In this notebook, we demonstrated Sentinel AI's neural plasticity system using the fully modular `NeuralPlasticityExperiment` class.

Key findings:
1. The system successfully implements **continuous neural plasticity** through multiple pruning cycles
2. Each cycle improves model structure by pruning less useful heads and potentially recovering valuable ones
3. The progressive refinement mimics how biological brains optimize neural pathways
4. Pruned models maintain or improve performance with fewer active heads
5. The entire pipeline works consistently across different environments

### Benefits of the Modular Architecture

The modular architecture in v0.0.64 provides significant advantages:

1. **Fully Encapsulated Functionality**: All plasticity operations are encapsulated in API methods
2. **No Code Duplication**: The same code paths handle both interactive steps and one-shot runs
3. **Presentation-Logic Separation**: Notebooks focus on presentation while modules handle logic
4. **Cross-Platform Compatibility**: The same code works reliably across standard CPUs, GPUs, and Apple Silicon
5. **Environment-Aware Visualization**: Automatically displays or saves visualizations based on execution context
6. **Continuous Plasticity Loop**: Multiple pruning cycles with comprehensive tracking in a single call
7. **Reproducibility**: Standardized experiments with consistent outputs

This approach mimics biological neural plasticity, where brains continuously form efficient neural pathways by pruning unused connections and strengthening useful ones over time."""
    nb.cells[23].source = conclusion
    changes_made = True
    print("Updated conclusion cell")

# Save the updated notebook
if changes_made:
    # Backup original file
    backup_path = notebook_path + ".bak"
    if os.path.exists(notebook_path):
        with open(notebook_path, 'r') as f_in:
            with open(backup_path, 'w') as f_out:
                f_out.write(f_in.read())
        print(f"Backed up original notebook to {backup_path}")
    
    # Write updated notebook
    nbformat.write(nb, notebook_path)
    print(f"Successfully updated notebook: {notebook_path}")
else:
    print("No changes were required to the notebook.")

print("Notebook update completed.")