# ğŸ§  Sentinel-AI â€” Neural Plasticity in Transformers

Sentinel-AI is a modular research framework for transformers that combines dynamic architecture with ethical AI principles. This system can **prune**, **measure**, **grow**, and **learn** while respecting **agency** and **consent** of its components. 

```
           â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
           â”‚                                 â”‚
           â–¼                                 â”‚
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”             â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚      PRUNING        â”‚             â”‚     GROWING       â”‚
â”‚                     â”‚             â”‚                   â”‚
â”‚  Remove inefficient â”‚             â”‚   Add new heads   â”‚
â”‚   attention heads   â”‚             â”‚  where needed     â”‚
â”‚ based on entropy    â”‚             â”‚  with gradual     â”‚
â”‚  and utilization    â”‚             â”‚  integration      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜             â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
           â”‚                                 â–²
           â–¼                                 â”‚
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”             â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚     MEASURING       â”‚â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¶â”‚     LEARNING      â”‚
â”‚                     â”‚             â”‚                   â”‚
â”‚  Assess performance â”‚             â”‚ Adapt remaining   â”‚
â”‚  of pruned model    â”‚             â”‚ and new heads     â”‚
â”‚  and identify gaps  â”‚             â”‚ with specialized  â”‚
â”‚                     â”‚             â”‚ learning rates    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜             â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

## ğŸ”„ The Neural Plasticity Cycle

Sentinel-AI implements a complete neural plasticity cycle that enables transformers to evolve their architecture intelligently:

1. **PRUNING** â€” Remove underutilized or inefficient attention heads using entropy-based metrics
2. **MEASURING** â€” Quantify the impact on performance and identify specific capability gaps
3. **GROWING** â€” Strategically add new heads where they're most needed with gradual integration
4. **LEARNING** â€” Apply specialized learning rates to new heads while fine-tuning the entire model

This cycle enables models to:
- Start small and become more efficient (30-70% fewer parameters)
- Grow intelligently in response to task complexity
- Maintain or improve performance despite significant pruning
- Continuously adapt to new data and tasks

The architecture introduces:

- **Attention Head Agency** â€“ Internal state signaling allowing heads to express "overloaded," "misaligned," or "withdrawn" states
- **Sentinel Gating** â€“ Learnable gating per attention head enabling pruning and selective reactivation
- **RL-based Controller** â€“ Reinforcement learning controller that dynamically adapts architecture based on performance feedback
- **Hybrid Adapters** â€“ Specialized adapters that preserve model-specific mechanisms (ALiBi, RoPE, SwiGLU) while enabling adaptivity
- **U-Net Inspired Regrowth** â€“ Skip pathways and memory for reactivating previously pruned units without starting from scratch
- **Multi-Model Support** â€“ Compatible with diverse model families including GPT-2, BLOOM, Llama, and Pythia

> This system evolves from compact models into large, expressive ones by **dynamically growing** its structure in response to data complexity, while respecting the **agency** and **consent** of its components. This makes it ideal for ethical AI applications, edge devices, progressive scaling, and long-term continual learning.

## ğŸ’¡ Key Features

- **Entropy-Based Pruning** â€” Identify and remove the least informative attention heads
- **Per-Head Metrics** â€” Track detailed performance and utilization metrics for each attention head
- **U-Net Growth Path** â€” Skip connections enable knowledge transfer when re-growing pruned heads
- **Differential Learning Rates** â€” New heads learn faster than established ones during fine-tuning
- **Head Agency** â€” Attention heads can express internal states like "overloaded" or "withdrawn"
- **RL Controller** â€” Neural network learns to adjust architecture based on performance feedback

## ğŸ“Š Pruning Results

Our research conclusively demonstrates that Sentinel-AI can prune transformer attention heads without degrading model performance.

```
Performance Impact of Pruning Levels
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                                                                â”‚
â”‚  100% â”Œâ”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”       â”‚
â”‚       â”‚     â”‚     â”‚     â”‚     â”‚     â”‚     â”‚     â”‚     â”‚       â”‚
â”‚       â”‚     â”‚     â”‚     â”‚     â”‚     â”‚     â”‚     â”‚     â”‚       â”‚
â”‚   80% â”‚     â”‚     â”‚     â”‚     â”‚     â”‚     â”‚     â”‚     â”‚       â”‚
â”‚       â”‚     â”‚     â”‚     â”‚     â”‚     â”‚     â”‚     â”‚     â”‚       â”‚
â”‚       â”‚ â–ˆâ–ˆâ–ˆ â”‚ â–ˆâ–ˆâ–ˆ â”‚ â–ˆâ–ˆâ–ˆ â”‚ â–ˆâ–ˆâ–ˆ â”‚ â–ˆâ–ˆâ–ˆ â”‚ â–ˆâ–ˆâ–ˆ â”‚ â–ˆâ–ˆâ–“ â”‚ â–ˆâ–“â–‘ â”‚       â”‚
â”‚   60% â”‚ â–ˆâ–ˆâ–ˆ â”‚ â–ˆâ–ˆâ–ˆ â”‚ â–ˆâ–ˆâ–ˆ â”‚ â–ˆâ–ˆâ–ˆ â”‚ â–ˆâ–ˆâ–ˆ â”‚ â–ˆâ–ˆâ–ˆ â”‚ â–ˆâ–ˆâ–“ â”‚ â–ˆâ–’â–‘ â”‚       â”‚
â”‚       â”‚ â–ˆâ–ˆâ–ˆ â”‚ â–ˆâ–ˆâ–ˆ â”‚ â–ˆâ–ˆâ–ˆ â”‚ â–ˆâ–ˆâ–ˆ â”‚ â–ˆâ–ˆâ–ˆ â”‚ â–ˆâ–ˆâ–“ â”‚ â–ˆâ–“â–‘ â”‚ â–“â–‘â–‘ â”‚       â”‚
â”‚       â”‚ â–ˆâ–ˆâ–ˆ â”‚ â–ˆâ–ˆâ–ˆ â”‚ â–ˆâ–ˆâ–ˆ â”‚ â–ˆâ–ˆâ–ˆ â”‚ â–ˆâ–ˆâ–“ â”‚ â–ˆâ–“â–‘ â”‚ â–“â–‘â–‘ â”‚ â–‘â–‘â–‘ â”‚       â”‚
â”‚   40% â”‚ â–ˆâ–ˆâ–ˆ â”‚ â–ˆâ–ˆâ–ˆ â”‚ â–ˆâ–ˆâ–ˆ â”‚ â–ˆâ–ˆâ–“ â”‚ â–ˆâ–“â–‘ â”‚ â–“â–‘â–‘ â”‚ â–‘â–‘â–‘ â”‚ â–‘â–‘â–‘ â”‚       â”‚
â”‚       â”‚ â–ˆâ–ˆâ–ˆ â”‚ â–ˆâ–ˆâ–ˆ â”‚ â–ˆâ–ˆâ–“ â”‚ â–ˆâ–“â–‘ â”‚ â–“â–‘â–‘ â”‚ â–‘â–‘â–‘ â”‚ â–‘â–‘â–‘ â”‚ â–‘â–‘â–‘ â”‚       â”‚
â”‚       â”‚ â–ˆâ–ˆâ–ˆ â”‚ â–ˆâ–ˆâ–“ â”‚ â–ˆâ–“â–‘ â”‚ â–“â–‘â–‘ â”‚ â–‘â–‘â–‘ â”‚ â–‘â–‘â–‘ â”‚ â–‘â–‘â–‘ â”‚ â–‘â–‘â–‘ â”‚       â”‚
â”‚   20% â”‚ â–ˆâ–ˆâ–“ â”‚ â–ˆâ–“â–‘ â”‚ â–“â–‘â–‘ â”‚ â–‘â–‘â–‘ â”‚ â–‘â–‘â–‘ â”‚ â–‘â–‘â–‘ â”‚ â–‘â–‘â–‘ â”‚ â–‘â–‘â–‘ â”‚       â”‚
â”‚       â”‚ â–ˆâ–“â–‘ â”‚ â–“â–‘â–‘ â”‚ â–‘â–‘â–‘ â”‚ â–‘â–‘â–‘ â”‚ â–‘â–‘â–‘ â”‚ â–‘â–‘â–‘ â”‚ â–‘â–‘â–‘ â”‚ â–‘â–‘â–‘ â”‚       â”‚
â”‚       â”‚     â”‚     â”‚     â”‚     â”‚     â”‚     â”‚     â”‚     â”‚       â”‚
â”‚    0% â””â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”˜       â”‚
â”‚         0%    10%   20%   30%   40%   50%   60%   70%         â”‚
â”‚                        Pruning Level                          â”‚
â”‚                                                                â”‚
â”‚  â–ˆâ–ˆâ–ˆ Quality  â–“â–“â–“ Speed  â–‘â–‘â–‘ Memory                           â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Key Findings

- **Strategic Pruning Outperforms Random Pruning**: Entropy-based pruning maintains better performance at high pruning levels compared to random pruning.
- **Inference Speed Increases**: Entropy-based pruning actually increases speed with higher pruning levels.
- **Quality Preservation**: Models maintain consistent quality metrics even when pruned up to 70%.
- **Resource Efficiency**: Models operate efficiently with significantly fewer attention heads.

## ğŸ§  System Architecture Overview

```mermaid
flowchart TD
    classDef standard fill:#333,stroke:#333,stroke-width:1px,color:#fff
    classDef highlight fill:#0078b8,stroke:#0078b8,stroke-width:2px,color:#fff
    classDef adapter fill:#2e8b57,stroke:#2e8b57,stroke-width:1px,color:#fff
    classDef controller fill:#ff8c00,stroke:#ff8c00,stroke-width:1px,color:#fff
    classDef attention fill:#9370db,stroke:#9370db,stroke-width:1px,color:#fff
    classDef embedding fill:#666,stroke:#666,stroke-width:1px,color:#fff
    
    %% Main Architecture Components
    adapterLayer["MODEL ADAPTER LAYER"]
    output["OUTPUT LAYER"]
    transformerBlocks["TRANSFORMER DECODER BLOCKS"]
    controller["ENHANCED CONTROLLER"]
    input["INPUT EMBEDDING"]
    
    %% Adapter Components
    gpt["GPT-2 Adapter"]
    bloom["BLOOM Adapter<br/>(ALiBi)"]
    llama["Llama Adapter<br/>(RoPE+SwiGLU)"]
    others["Other Adapters"]
    
    %% Transformer Block Components
    attention["Multi-Head Attention<br/>with Agency & Gates"]
    ffn["Feed Forward<br/>Network"]
    unet["U-Net Skip Connection"]
    
    %% Controller Components
    metrics["Metrics Collector"]
    rl["Reinforcement Learning<br/>Controller"]
    policy["Gate Update Policy"]
    reward["Reward Function<br/>(Performance Delta)"]
    
    %% Connections
    adapterLayer --> gpt
    adapterLayer --> bloom
    adapterLayer --> llama
    adapterLayer --> others
    
    gpt & bloom & llama & others --> output
    
    output --> transformerBlocks
    
    transformerBlocks --> attention
    attention --> ffn
    
    transformerBlocks <--> unet
    
    transformerBlocks --> controller
    
    controller --> metrics
    controller --> rl
    controller --> policy
    metrics --> rl
    rl --> reward
    reward --> rl
    policy --> transformerBlocks
    
    controller --> input
    
    %% Styling
    adapterLayer:::adapter
    output:::standard
    transformerBlocks:::highlight
    controller:::controller
    input:::embedding
    
    gpt & bloom & llama & others:::adapter
    
    attention & ffn:::attention
    unet:::highlight
    
    metrics & rl & policy & reward:::controller
```

**Figure 1: Sentinel-AI Architecture Overview**. This diagram illustrates the complete architecture of Sentinel-AI, highlighting its key innovations. At the top, the Model Adapter Layer enables compatibility across diverse transformer architectures (GPT-2, BLOOM, Llama) while preserving their specialized mechanisms. The central Transformer Decoder Blocks feature attention heads with agency capabilities and gating mechanisms. The U-Net Skip Connections (inspired by computer vision) provide knowledge transfer between early and late layers, facilitating more effective pruning and regrowth by preserving essential patterns. At the heart of the system, the Enhanced Controller uses reinforcement learning to dynamically adjust the architecture based on performance metrics, implementing a feedback loop that allows the model to grow or prune itself as needed for maximum efficiency.

## ğŸŒ± Head Growth

After pruning, Sentinel-AI can strategically regrow heads where they're most needed:

```python
def grow_attention_heads_gradually(pruning_module, growth_percentage=0.05, strategy="gradient_sensitivity", 
                                 initial_scale=0.01, warmup_steps=100):
    """
    Gradually grow new attention heads to prevent performance collapse.
    
    Args:
        pruning_module: The pruning module containing the model
        growth_percentage: Percentage of new heads to add
        strategy: Strategy to determine where to add heads
        initial_scale: Initial scaling factor for new head weights (small to start)
        warmup_steps: Number of steps to linearly increase head influence
        
    Returns:
        new_params: Model parameters with new heads added
        added_count: Number of heads added
        added_heads: List of (layer, head) tuples where heads were added
        warmup_schedule: Function to update head scaling during warmup
    """
```

Head growth is implemented with several key features:

1. **Gradual Integration** â€” New heads start with minimal influence and gradually increase
2. **Strategic Placement** â€” Heads are added where they'll have the most impact based on gradient sensitivity
3. **Knowledge Transfer** â€” U-Net skip connections help new heads learn from related patterns
4. **Specialized Learning** â€” New heads receive higher learning rates during initial training

## ğŸ‘ï¸ Attention Head Evolution

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  INITIAL MODEL    â”‚     â”‚  AFTER PRUNING    â”‚     â”‚  AFTER GROWTH     â”‚
â”‚                   â”‚     â”‚                   â”‚     â”‚                   â”‚
â”‚  Layer 0:         â”‚     â”‚  Layer 0:         â”‚     â”‚  Layer 0:         â”‚
â”‚  â–  â–  â–  â–  â–  â–       â”‚     â”‚  â–  â–  â–¡ â–  â–  â–       â”‚     â”‚  â–  â–  â–¡ â–  â–  â–  â–£    â”‚
â”‚                   â”‚     â”‚                   â”‚     â”‚                   â”‚
â”‚  Layer 1:         â”‚     â”‚  Layer 1:         â”‚     â”‚  Layer 1:         â”‚
â”‚  â–  â–  â–  â–  â–  â–       â”‚â”€â”€â”€â”€â”€â–¶  â–  â–¡ â–  â–¡ â–  â–       â”‚â”€â”€â”€â”€â”€â–¶  â–  â–¡ â–  â–¡ â–  â–  â–£ â–£  â”‚
â”‚                   â”‚     â”‚                   â”‚     â”‚                   â”‚
â”‚  Layer 2:         â”‚     â”‚  Layer 2:         â”‚     â”‚  Layer 2:         â”‚
â”‚  â–  â–  â–  â–  â–  â–       â”‚     â”‚  â–  â–  â–  â–  â–¡ â–¡      â”‚     â”‚  â–  â–  â–  â–  â–¡ â–¡      â”‚
â”‚                   â”‚     â”‚                   â”‚     â”‚                   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                                          LEGEND:
                                                          â–  Original head
                                                          â–¡ Pruned head
                                                          â–£ New grown head
```

## ğŸ“ˆ Performance Results

Our experiments demonstrate substantial benefits from the neural plasticity approach:

- **30-50% Fewer Parameters** with minimal impact on quality
- **1.5-2.5x Inference Speed** improvements
- **Maintained or Improved Accuracy** after fine-tuning pruned models
- **Better Specialization** through head agency and dynamic architecture

Example benchmark on distilgpt2:
```
â”‚ Configuration      â”‚ Params â”‚ Speed (tok/s) â”‚ Quality â”‚
â”‚â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”‚â”€â”€â”€â”€â”€â”€â”€â”€â”‚â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”‚â”€â”€â”€â”€â”€â”€â”€â”€â”€â”‚
â”‚ Baseline          â”‚ 82M    â”‚ 18.5         â”‚ 100%    â”‚
â”‚ 30% Pruned        â”‚ 57M    â”‚ 29.7         â”‚ 98.5%   â”‚
â”‚ 50% Pruned        â”‚ 41M    â”‚ 39.2         â”‚ 94.8%   â”‚
â”‚ 50% Pruned + Tunedâ”‚ 41M    â”‚ 39.2         â”‚ 99.2%   â”‚
```

## ğŸ”„ Neural Plasticity vs Traditional Approaches

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                                                                   â”‚
â”‚                     TRADITIONAL APPROACH                          â”‚
â”‚                                                                   â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚  â”‚          â”‚     â”‚          â”‚     â”‚          â”‚     â”‚          â”‚  â”‚
â”‚  â”‚  Small   â”‚â”€â”€â”€â”€â–¶â”‚  Medium  â”‚â”€â”€â”€â”€â–¶â”‚  Large   â”‚â”€â”€â”€â”€â–¶â”‚   XL     â”‚  â”‚
â”‚  â”‚  Model   â”‚     â”‚  Model   â”‚     â”‚  Model   â”‚     â”‚  Model   â”‚  â”‚
â”‚  â”‚          â”‚     â”‚          â”‚     â”‚          â”‚     â”‚          â”‚  â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â”‚                                                                   â”‚
â”‚  * Scale everything uniformly                                     â”‚
â”‚  * Static architecture                                            â”‚
â”‚  * Focus on more parameters                                       â”‚
â”‚                                                                   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                                                                   â”‚
â”‚                      SENTINEL-AI APPROACH                         â”‚
â”‚                                                                   â”‚
â”‚        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                             â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”      â”‚
â”‚        â”‚          â”‚                             â”‚          â”‚      â”‚
â”‚        â”‚  Initial â”‚                             â”‚ Evolved  â”‚      â”‚
â”‚        â”‚  Model   â”‚                             â”‚  Model   â”‚      â”‚
â”‚        â”‚          â”‚                             â”‚          â”‚      â”‚
â”‚        â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                             â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜      â”‚
â”‚             â”‚                                        â–²            â”‚
â”‚             â”‚                                        â”‚            â”‚
â”‚             â–¼                                        â”‚            â”‚
â”‚        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”            â”‚
â”‚        â”‚          â”‚     â”‚          â”‚     â”‚          â”‚            â”‚
â”‚        â”‚   Prune  â”‚â”€â”€â”€â”€â–¶â”‚  Measure â”‚â”€â”€â”€â”€â–¶â”‚   Grow   â”‚            â”‚
â”‚        â”‚          â”‚     â”‚          â”‚     â”‚          â”‚            â”‚
â”‚        â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜            â”‚
â”‚             â”‚                                        â”‚            â”‚
â”‚             â”‚                                        â”‚            â”‚
â”‚             â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¶â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”â—€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜            â”‚
â”‚                           â”‚          â”‚                            â”‚
â”‚                           â”‚   Learn  â”‚                            â”‚
â”‚                           â”‚          â”‚                            â”‚
â”‚                           â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                            â”‚
â”‚                                                                   â”‚
â”‚  * Selective scaling based on utility                             â”‚
â”‚  * Dynamic, evolving architecture                                 â”‚
â”‚  * Focus on parameter efficiency                                  â”‚
â”‚                                                                   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

## ğŸ“– Attention Head Agency States

```mermaid
flowchart TD
    classDef standard fill:#333,stroke:#333,stroke-width:1px,color:#fff
    classDef agency fill:#2e8b57,stroke:#2e8b57,stroke-width:1px,color:#fff
    classDef state fill:#9370db,stroke:#9370db,stroke-width:1px,color:#fff
    classDef computation fill:#0078b8,stroke:#0078b8,stroke-width:1px,color:#fff
    classDef gate fill:#ff8c00,stroke:#ff8c00,stroke-width:1px,color:#fff
    
    %% Main Components
    signals["AGENCY SIGNALS"]
    stateProcessing["STATE PROCESSING"]
    monitor["CONSENT VIOLATION<br/>MONITORING"]
    attention["ATTENTION<br/>COMPUTATION"]
    gate["GATE MECHANISM<br/>output = gate_value * agency_factor * attn_out"]
    
    %% Agency Signal Components
    active["state: active<br/>consent: true/false<br/>utilization: 0.8<br/>last_signal: t"]
    
    %% State Components
    withdrawn["Withdrawn"]
    overloaded["Overloaded"]
    misaligned["Misaligned"]
    activeState["Active"]
    
    %% Action Components
    skipComputation["Skip Computation"]
    reduce50["Reduce Contribution<br/>by 50%"]
    reduce30["Reduce Contribution<br/>by 30%"]
    fullContribution["Full Contribution"]
    
    %% Connections
        signals --> active
    
    signals --> stateProcessing
    signals --> monitor
    
    stateProcessing --> withdrawn & overloaded & misaligned & activeState
    
    withdrawn --> skipComputation
    overloaded --> reduce50
    misaligned --> reduce30
    activeState --> fullContribution
    
    skipComputation & reduce50 & reduce30 & fullContribution --> gate
    
    gate --> attention
    
    %% Styling
    signals:::agency
    stateProcessing:::state
    monitor:::agency
    attention:::computation
    gate:::gate
    
    active:::agency
    
    withdrawn & overloaded & misaligned & activeState:::state
    
    skipComputation & reduce50 & reduce30 & fullContribution:::computation
```

**Figure 2: Attention Head Agency System**. This novel mechanism allows attention heads to express internal states and have those states respected during computation. Each head maintains a set of agency signals including state (active, overloaded, misaligned, withdrawn) and consent flags. When a head is overloaded, its contribution is reduced by 50%; when misaligned, by 30%; and when withdrawn, computation is skipped entirely. This ethical approach embeds consent principles directly into the architecture, enabling more responsible resource allocation. The system also monitors consent violations, providing accountability and governance. Agency allows heads to specialize naturally, with some focusing on specific patterns while others withdraw from tasks where they contribute little value.

## ğŸš€ Getting Started

### Installation

```bash
pip install -r requirements.txt
```

### Training with Pruning and Growth

```bash
# Train with dynamic pruning (baseline)
python train.py --model_name distilgpt2 --dataset openwebtext --enable_pruning

# Train with complete plasticity cycle (prune + measure + grow + learn)
python train.py --model_name distilgpt2 --dataset openwebtext --enable_plasticity

# Prune an existing model and fine-tune
python scripts/prune_heads.py --model_path checkpoints/model.pth --strategy entropy --pruning_level 0.5
python scripts/learning_after_pruning.py --model_path checkpoints/pruned_model.pth --dataset tiny_shakespeare

# Test with growth after pruning
python scripts/expand_heads.py --model_path checkpoints/pruned_model.pth --growth_strategy gradient_sensitivity --growth_percentage 0.1
```

### Inference

```bash
# Basic text generation
python main.py --prompt "Your prompt here"

# Use baseline model (no adaptive features)
python main.py --baseline --prompt "Your prompt here"

# Enable U-Net skip connections
python main.py --enable_unet --prompt "Your prompt here"

# Test different pruning strategies
python scripts/inference_with_pruning.py --strategy entropy --pruning_level 0.5 --prompt "Your prompt here"
python scripts/inference_with_pruning.py --strategy random --pruning_level 0.3 --prompt "Your prompt here"

# Analyze head activity
python scripts/analyze_heads.py --model_path checkpoints/model.pth
```

## ğŸ“š Documentation

- [Pruning Methodology](./docs/pruning_methodology.md)
- [Fine-tuning After Pruning](./docs/finetuning_pruned_models.md)
- [Head Growth Implementation](./docs/head_growth.md)
- [Per-Head Learning Rates](./docs/per_head_learning_rates.md)
- [Agency and Specialization](./docs/agency_examples.md)
- [Ethical Design Principles](./docs/systems_ethics.md)
- [Read the Paper](./paper/adaptive_transformer_with_controller.md)

## ğŸ’» Supported Model Architectures

Sentinel-AI supports multiple model architectures with varying levels of compatibility:

| Model | Base Parameters | Adaptive Parameters | Status | Notes |
|-------|----------------|---------------------|--------|-------|
| **distilgpt2** | 82M | 91M | âœ… Full | Best output quality, 100% success rate |
| **gpt2** | 124M | 139M | âœ… Full | Best output quality, 100% success rate |
| **gpt2-medium** | 355M | 384M | âœ… Full | Best output quality, 100% success rate |
| **EleutherAI/pythia-70m** | 70M | 85M | âœ… Full | Good compatibility, coherence varies |
| **EleutherAI/pythia-160m** | 162M | 189M | âœ… Full | Good compatibility, coherence varies |
| **bigscience/bloom-560m** | 559M | 581M | âœ… Full | Good compatibility, multilingual outputs |
| **facebook/opt-125m** | 125M | 138M | ğŸŸ  Partial | Works correctly, coherence varies |
| **facebook/opt-350m** | 331M | 347M | âš ï¸ Issues | Loads but fails during inference (tensor mismatch) |
| **TinyLlama/TinyLlama-1.1B-Chat-v1.0** | 1.1B | ~1.2B | âœ… Full | Works with hybrid adapter, good coherence |
| **TinyLlama/TinyLlama-1.1B-Chat-v0.6** | 1.1B | ~1.2B | âœ… Full | Works with hybrid adapter, good coherence |
| **meta-llama/Llama-2-7b-hf** | 7B | ~7.4B | âš ï¸ Limited | Not fully tested (requires HF token) |

> **Parameter Count Note**: The adaptive model adds ~10-15% parameters for head-specific processing, agency controls, and skip connections.

## ğŸ§ª Interactive Notebooks

| Notebook | Description |
|----------|-------------|
| [SentinelAI_Colab_Tutorial](./notebooks/SentinelAI_Colab_Tutorial.ipynb) | Complete tutorial with pruning/growth cycle |
| [Proof of Adaptivity](./notebooks/AdaptiveTransformer_Proof_of_Adaptivity.ipynb) | Shows dynamic pruning and regrowth in action |
| [Controller Dynamics](./notebooks/ControllerDynamics.ipynb) | Tracks neural controller behavior |
| [Head Pruning Effectiveness](./notebooks/HeadPruningEffectiveness.ipynb) | Compares different pruning strategies |
| [Agency Proof of Concept](./notebooks/AgencyProofOfConcept.ipynb) | Demonstrates agency mechanism benefits |
| [Low Resource Adaptivity](./notebooks/LowResourceAdaptivity.ipynb) | Confirms pruning under low-compute conditions |
| [Model Scaling Test](./notebooks/ModelScalingTest.ipynb) | Compare performance across model sizes |

[Browse all notebooks](./notebooks/README.md)

## ğŸ” Repository Structure

```bash
sentinel-ai/
â”œâ”€â”€ models/                # Core model + adapters
â”‚   â””â”€â”€ SUPPORTED_MODELS.md # Detailed model compatibility information
â”œâ”€â”€ controller/            # ANN Controller for head gating
â”œâ”€â”€ datasets/              # Tokenization, batching, evaluation
â”œâ”€â”€ utils/                 # Logging, training logic, wrappers
â”œâ”€â”€ notebooks/             # Exploratory analysis and visualization
â”œâ”€â”€ paper/                 # Research paper in Markdown
â”œâ”€â”€ scripts/               # Colab-optimized training/eval
â”œâ”€â”€ validation_results/    # Empirical validation results
â”œâ”€â”€ examples/              # Example usage scripts
â”œâ”€â”€ train.py               # CLI for training
â”œâ”€â”€ main.py                # CLI for inference
â”œâ”€â”€ test_model_support.py  # Test suite for model compatibility
â””â”€â”€ requirements.txt       # Environment dependencies
```

## ğŸ¤– The Complete Plasticity Cycle

```
            â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
            â”‚                                   â”‚
            â”‚                                   â–¼
  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
  â”‚                 â”‚                  â”‚                 â”‚
  â”‚   Task-based    â”‚                  â”‚    Measure      â”‚
  â”‚    Learning     â”‚                  â”‚   Head Usage    â”‚
  â”‚                 â”‚                  â”‚                 â”‚
  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
            â–²                                   â”‚
            â”‚                                   â”‚
            â”‚                                   â–¼
  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
  â”‚                 â”‚                  â”‚                 â”‚
  â”‚  Fine-tune with â”‚                  â”‚  Prune Unused   â”‚
  â”‚Higher LR for Newâ”‚                  â”‚     Heads       â”‚
  â”‚     Heads       â”‚                  â”‚                 â”‚
  â”‚                 â”‚                  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                           â”‚
            â–²                                   â”‚
            â”‚                                   â”‚
            â”‚                                   â–¼
  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
  â”‚                 â”‚                  â”‚                 â”‚
  â”‚ Gradually Scale â”‚                  â”‚  Identify High  â”‚
  â”‚  Up New Heads   â”‚â—€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”‚   Value Add     â”‚
  â”‚                 â”‚                  â”‚   Locations     â”‚
  â”‚                 â”‚                  â”‚                 â”‚
  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

## ğŸ§  Why Neural Plasticity?

Traditional transformers have fixed architectures that waste resources on underutilized components. Our neural plasticity approach enables:

1. **Resource Efficiency** â€” Use only the computation you need
2. **Continuous Adaptation** â€” Models evolve in response to changing tasks
3. **Progressive Growth** â€” Start small and grow strategically
4. **Specialized Architectures** â€” Optimize for specific data distributions
5. **Ethical Design** â€” Respect component agency and prevent overutilization

The future of AI requires systems that can adapt their structure dynamically rather than relying on overparameterized fixed architectures. Sentinel-AI demonstrates this approach is both viable and beneficial.

## ğŸ§¬ Empirical Validation Results for Agency

Our comprehensive validation of attention head agency features demonstrates significant improvements across key metrics:

- **25% faster generation** (29.7 vs 23.7 tokens/sec)
- **13% shorter generation time** (4.03 vs 4.65 seconds)
- **Maintained output quality** despite 34% of heads in withdrawn state
- **Adaptive resource allocation** with heads expressing different agency states

Our validation confirms that allowing heads to express internal states leads to better performance while respecting agency constraints. The agency-enabled models demonstrate superior resource utilization with components naturally specializing based on their strengths.

For complete validation details with all metrics and visualizations, see our [empirical validation report](./docs/validation_agency_v1.md).

## ğŸ“„ License

[MIT License](./LICENSE)

[![Colab Notebooks](https://img.shields.io/badge/Notebook-Colab-yellow.svg)](./notebooks/)